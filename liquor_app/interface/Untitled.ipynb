{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ed8c48c-42e5-407c-9243-4e2c9f2baaac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'create_sequences_padre' from 'liquor_app.ml_logic.preprocessor' (/home/pipesco93/.pyenv/versions/3.10.6/envs/liquor_demand_forecasting/lib/python3.10/site-packages/liquor_app/ml_logic/preprocessor.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mliquor_app\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml_logic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_data_with_cache, clean_data, load_data_to_bq\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mliquor_app\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml_logic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m initialize_model, compile_model, train_model, evaluate_model\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mliquor_app\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml_logic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m preprocess_features, create_sequences_padre\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mliquor_app\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml_logic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_model, save_model\u001b[38;5;66;03m#, save_results\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'create_sequences_padre' from 'liquor_app.ml_logic.preprocessor' (/home/pipesco93/.pyenv/versions/3.10.6/envs/liquor_demand_forecasting/lib/python3.10/site-packages/liquor_app/ml_logic/preprocessor.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdb\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))  # Ensure the correct root is included\n",
    "os.chdir(os.path.abspath(\"..\"))\n",
    "\n",
    "from pathlib import Path\n",
    "from dateutil.parser import parse\n",
    "\n",
    "from liquor_app.params import *\n",
    "from liquor_app.ml_logic.data import get_data_with_cache, clean_data, load_data_to_bq\n",
    "from liquor_app.ml_logic.model import initialize_model, compile_model, train_model, evaluate_model\n",
    "from liquor_app.ml_logic.preprocessor import preprocess_features, create_sequences_padre\n",
    "from liquor_app.ml_logic.registry import load_model, save_model#, save_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaf08a5-e952-4e47-8287-4933222a81bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(min_date='2013-01-01', max_date='2023-06-30'):\n",
    "    query = f\"\"\"\n",
    "        with clean_data as (\n",
    "                select * EXCEPT (store_number, zip_code, category, vendor_number, county_number),\n",
    "                CAST(store_number AS NUMERIC) as store_number ,\n",
    "                CAST(zip_code AS NUMERIC) as zip_code ,\n",
    "                CAST(category AS NUMERIC) as category,\n",
    "                CAST(vendor_number AS NUMERIC) as vendor_number\n",
    "                from `bigquery-public-data.iowa_liquor_sales.sales`\n",
    "                where date >= '{min_date}' and date <= '{max_date}'\n",
    "                --and CAST(vendor_number AS NUMERIC) in (260,421,65,370,85,434,35,301,259,115,395,55,420,205,380,192,297,300,255,389)\n",
    "                ORDER BY date ASC\n",
    "        ),\n",
    "        distinct_vendor as (\n",
    "                select\n",
    "                CAST(vendor_number AS NUMERIC) as vendor_number,\n",
    "                ARRAY_TO_STRING(ARRAY_AGG(vendor_name ORDER BY date DESC LIMIT 1),\"\") as vendor_name\n",
    "                from `bigquery-public-data.iowa_liquor_sales.sales`\n",
    "                group by 1\n",
    "        ),\n",
    "        distinct_category as (\n",
    "                select\n",
    "                CAST(category AS NUMERIC) as category,\n",
    "                ARRAY_TO_STRING(ARRAY_AGG(category_name ORDER BY date DESC LIMIT 1),\"\") as category_name\n",
    "                from `bigquery-public-data.iowa_liquor_sales.sales`\n",
    "                group by 1\n",
    "        ),\n",
    "        distinct_store as (\n",
    "                select\n",
    "                CAST(store_number AS NUMERIC) as store_number,\n",
    "                ARRAY_TO_STRING(ARRAY_AGG(store_name ORDER BY date DESC LIMIT 1),\"\") as store_name\n",
    "                from `bigquery-public-data.iowa_liquor_sales.sales`\n",
    "                group by 1\n",
    "        ), clean_data2 as (\n",
    "        select\n",
    "                cd.* EXCEPT (vendor_name, category_name, store_name),\n",
    "                dv.vendor_name,\n",
    "                dc.category_name,\n",
    "                ds.store_name\n",
    "        from clean_data cd\n",
    "        left join distinct_vendor dv on cd.vendor_number = dv.vendor_number\n",
    "        left join distinct_category dc on cd.category = dc.category\n",
    "        left join distinct_store ds on cd.store_number = ds.store_number\n",
    "        ), group_and_others as (\n",
    "        SELECT date,\n",
    "        case when county in ('POLK','LINN','SCOTT','BLACK HAWK','JOHNSON') then county else 'OTHER' END AS county, #'POTTAWATTAMIE','DUBUQUE','STORY','WOODBURY','DALLAS'\n",
    "        CASE\n",
    "        WHEN category_name like '%RUM%' THEN 'RUM'\n",
    "        WHEN category_name like '%VODKA%' THEN 'VODKA'\n",
    "        WHEN category_name like '%WHISK%' or  category_name like '%SCOTCH%' THEN 'WHISKY'\n",
    "        WHEN category_name like '%TEQUILA%' or category_name like '%MEZCAL%' THEN 'TEQUILA_MEZCAL'\n",
    "        WHEN category_name like '%LIQUEUR%' THEN 'LIQUEURS'\n",
    "        WHEN category_name like '%GIN%' THEN 'GIN'\n",
    "        else 'OTROS'\n",
    "        end as category_name,\n",
    "        case when vendor_name in ('SAZERAC COMPANY  INC','DIAGEO AMERICAS','HEAVEN HILL BRANDS','LUXCO INC','JIM BEAM BRANDS','FIFTH GENERATION INC','PERNOD RICARD USA','MCCORMICK DISTILLING CO.','BACARDI USA INC','E & J GALLO WINERY') then vendor_name else 'OTHER' END as vendor_name,\n",
    "        sum(bottles_sold) as bottles_sold\n",
    "        FROM clean_data2\n",
    "        group by 1,2,3,4\n",
    "        ), summary as (\n",
    "        select\n",
    "        * EXCEPT (vendor_name)\n",
    "        from group_and_others\n",
    "        where lower(vendor_name) like '%bacardi%'\n",
    "        ), combinations as (\n",
    "        SELECT\n",
    "          *\n",
    "          FROM UNNEST(GENERATE_DATE_ARRAY('{min_date}', '{max_date}', INTERVAL 1 DAY)) as date\n",
    "          cross join (select distinct category_name from summary) a\n",
    "          cross join (select distinct county from summary) b\n",
    "          ), data_combinations as (\n",
    "        select c.*,\n",
    "        date_trunc(c.date, WEEK) as date_week,\n",
    "          coalesce(s.bottles_sold,0) as bottles_sold\n",
    "          from combinations c\n",
    "          left join summary s on c.date = s.date and c.category_name = s.category_name and c.county = s.county\n",
    "          )\n",
    "          select date_week, category_name, county,\n",
    "          extract(YEAR FROM date_week) as week_year,\n",
    "          extract(WEEK(MONDAY) from date_week) as week_of_year,\n",
    "           sum(bottles_sold) as bottles_sold\n",
    "           from data_combinations\n",
    "           group by 1,2,3,4,5\n",
    "           order by county asc, category_name asc, date_week asc\n",
    "\n",
    "    \"\"\"\n",
    "    print(RAW_DATA_PATH)\n",
    "\n",
    "    data = get_data_with_cache(\n",
    "        gcp_project = GCP_PUBLIC_DATA,\n",
    "        query = query,\n",
    "        cache_path=Path(RAW_DATA_PATH).joinpath(\"data.csv\"),\n",
    "        data_has_header=True\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "#def crear_secuencias_rnn(data):\n",
    "#    pass\n",
    "#    #return X, y\n",
    "\n",
    "def preprocess(data) -> None:\n",
    "    columnas_target = data[[\"bottles_sold\"]]\n",
    "    columnas_apoyo = data[['category_name','county']]\n",
    "\n",
    "    data_processed,col_names = preprocess_features(data,True)\n",
    "    print(\"✅ Data Proccesed \")\n",
    "\n",
    "    # # # LOAD A DATAFRAME ONTO BIGQUERY CONTAINING [PICKUP_DATETIME, X_PROCESSED, Y]\n",
    "    # # # USING DATA.LOAD_DATA_TO_BQ()\n",
    "\n",
    "    data_processed = pd.DataFrame(\n",
    "        data_processed,\n",
    "        columns=col_names\n",
    "    )\n",
    "\n",
    "    data_processed = pd.concat([data_processed, columnas_apoyo, columnas_target], axis=\"columns\", sort=False)\n",
    "    data_processed.columns = data_processed.columns.str.replace(\" \", \"_\")\n",
    "    # data_processed.rename(columns={'remainder__date_ordinal':'date_ordinal'}, inplace=True)\n",
    "    # #data_processed = pd.DataFrame(np.concatenate((dates, X_processed, y), axis=1))\n",
    "\n",
    "    processed_path = Path(PROCESSED_DATA_PATH).joinpath(\"data_processed.csv\")\n",
    "    data_processed.to_csv(processed_path, header=True, index=False)\n",
    "\n",
    "    print(f\"✅ Raw data saved as {RAW_DATA_PATH}\")\n",
    "    print(f\"✅ Processed data saved as {PROCESSED_DATA_PATH}\")\n",
    "    print(\"✅ preprocess() done\")\n",
    "    return data_processed\n",
    "\n",
    "\n",
    "def train(min_date:str = '2023-01-01',\n",
    "        max_date:str = '2023-03-31',\n",
    "        split_ratio: float = 0.20, # 0.02 represents ~ 1 month of validation data on a 2009-2015 train set\n",
    "        learning_rate=0.0005,\n",
    "        batch_size = 256,\n",
    "        patience = 10\n",
    "    ) -> float:\n",
    "\n",
    "    \"\"\"\n",
    "    - Download processed data from your BQ table (or from cache if it exists)\n",
    "    - Train on the preprocessed dataset (which should be ordered by date)\n",
    "    - Store training results and model weights\n",
    "\n",
    "    Return val_mae as a float\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n⭐️ Use case: train\")\n",
    "    print( \"\\nLoading preprocessed validation data...\")\n",
    "\n",
    "    #min_date = parse(min_date).strftime('%Y-%m-%d') # e.g '2009-01-01'\n",
    "    #max_date = parse(max_date).strftime('%Y-%m-%d') # e.g '2009-01-01'\n",
    "\n",
    "    # Load processed data using `get_data_with_cache` in chronological order\n",
    "    # Try it out manually on console.cloud.google.com first!\n",
    "\n",
    "    query = f\"\"\"\n",
    "        SELECT 'hello world'\n",
    "        \"\"\"\n",
    "\n",
    "    data = get_data_with_cache(GCP_PUBLIC_DATA,\n",
    "        query,\n",
    "        cache_path=Path(PROCESSED_DATA_PATH).joinpath(\"data_processed.csv\"),\n",
    "        data_has_header=True\n",
    "    )\n",
    "\n",
    "    #tomar solo 10% de la data\n",
    "    #data = data.sample(frac=0.4, random_state=42)  # Tomar solo el 10% de los datos\n",
    "    columnas_target = data[[\"bottles_sold\"]].copy()\n",
    "    columnas_apoyo = data[['category_name','county']].copy()\n",
    "\n",
    "    data_preproc = data.iloc[:,:-(len(columnas_target.columns)+len(columnas_apoyo.columns)+1)]\n",
    "\n",
    "    print(f\"creando secuencias para modelo RNN...\")\n",
    "    X, y = create_sequences_padre(data_preproc, columnas_target, past_steps=52, future_steps=12)\n",
    "    print(\"✅ Secuencias creadas \")\n",
    "\n",
    "    split_index = int((1-split_ratio) * len(X))\n",
    "    X_train, X_val = X[:split_index], X[split_index:]\n",
    "    y_train, y_val = y[:split_index], y[split_index:]\n",
    "    print(\"✅ Train/Val Split created \")\n",
    "\n",
    "    print(\"Input shape X train completo:\", X_train.shape)\n",
    "    print(\"Input shape y train completo:\", y_train.shape)\n",
    "    print(\"Input shape X train[1:]:\", X_train.shape[1:])\n",
    "    print(\"Input shape X val completo:\", X_val.shape)\n",
    "    print(\"Input shape y train completo:\",y_train.shape)\n",
    "    print(\"Input shape y val completo:\",y_val.shape)\n",
    "\n",
    "\n",
    "    print(X_train.dtype)\n",
    "    print(type(X_train))\n",
    "\n",
    "    print(f\"inicializando modelo\")\n",
    "    model = initialize_model(input_shape=X_train.shape[1:])\n",
    "    model = compile_model(model, learning_rate=learning_rate)\n",
    "\n",
    "    print(\"✅ Model compiled succesfully\")\n",
    "\n",
    "    model,history = train_model(\n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        patience=patience,\n",
    "        validation_data=(X_val, y_val)\n",
    "    )\n",
    "\n",
    "    if 'val_mae' in history.history:\n",
    "        val_mae = np.min(history.history['val_mae'])\n",
    "    else:\n",
    "        val_mae = np.min(history.history['val_loss'])  # Use validation loss instead\n",
    "\n",
    "    print(\"val_mae:\", val_mae)\n",
    "\n",
    "    # params = dict(\n",
    "    #     context=\"train\",\n",
    "    #     row_count=len(X_train),\n",
    "    # )\n",
    "\n",
    "    # Save results on the hard drive using taxifare.ml_logic.registry\n",
    "    #save_results(params=params, metrics=dict(mae=val_mae))\n",
    "\n",
    "    # Save model weight on the hard drive (and optionally on GCS too!)\n",
    "    save_model(model=model)\n",
    "\n",
    "    print(\"✅ train() done \\n\")\n",
    "\n",
    "    return val_mae, X_val, y_train\n",
    "\n",
    "\n",
    "def evaluate(*args) -> float:\n",
    "    pass\n",
    "\n",
    "def pred(X_pred:np.ndarray = None) -> np.ndarray:\n",
    "\n",
    "    if X_pred is None:\n",
    "        print(f\"cargando datos dummy para X_pred\")\n",
    "        data = get_data_with_cache(GCP_PUBLIC_DATA,\n",
    "        query = 'hi',\n",
    "        cache_path=Path(PROCESSED_DATA_PATH).joinpath(\"data_processed.csv\"),\n",
    "        data_has_header=True\n",
    "        )\n",
    "        # data = data.iloc[-20:, :]\n",
    "        print(f\"{data.shape}\")\n",
    "\n",
    "        columnas_target = data[[\"bottles_sold\"]].copy()\n",
    "        columnas_apoyo = data[['category_name','county']].copy()\n",
    "        data_preproc = data.iloc[:,:-(len(columnas_target.columns)+len(columnas_apoyo.columns)+1)]\n",
    "        X,y = create_sequences(data_preproc, columnas_apoyo, columnas_target, past_steps=52, future_steps=12)\n",
    "        split_ratio = 0.2\n",
    "        split_index = int((1-split_ratio) * len(X))\n",
    "        X_prep = X[split_index:]\n",
    "        y_prep = y[split_index:]\n",
    "        print(\"✅ Pred data created \")\n",
    "        print(\"X_prep shape:\", X_prep.shape)\n",
    "\n",
    "        model = load_model()\n",
    "        assert model is not None\n",
    "        print(f\"modelo cargado\")\n",
    "\n",
    "        print(f\"predicting X_pred\")\n",
    "        y_pred = model.predict(X_prep)\n",
    "\n",
    "        print(\"\\n✅ prediction done: \", y_pred, y_pred.shape, \"\\n\")\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "    print(f\"cargando modelo\")\n",
    "    model = load_model()\n",
    "    assert model is not None\n",
    "    print(f\"modelo cargado\")\n",
    "\n",
    "    print(\"X_pred shape:\", X_pred.shape)\n",
    "    print(f\"predicting X_pred\")\n",
    "    y_pred = model.predict(X_pred)\n",
    "\n",
    "    print(\"\\n✅ prediction done: \", y_pred, y_pred.shape, \"\\n\")\n",
    "    return y_pred\n",
    "\n",
    "def pred_future(model, last_sequence, future_steps=3):\n",
    "    pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data = get_data()\n",
    "    preprocess(data)\n",
    "    val_mae, X_val = train()\n",
    "    #evaluate()\n",
    "    pred = pred(X_val)\n",
    "    print(pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
